## RLHF Case Studies Using Sociological Framework  
Dr. Jeremy Hein  
PhD Sociologist | AI Trainer | Educator

## Overview  
This repository showcases my applied work in AI training and alignment, drawing on 30+ years of sociological expertise. Since 2025, I’ve contributed to RLHF projects at Snorkel AI, Outlier AI, and Handshake AI — designing edge-case prompts, evaluating model reasoning, and applying inclusive pedagogy to improve large language models (LLMs). My approach integrates symbolic interactionism, comparative religion, and musicology to support neurodiverse learners and human-centered AI development.

## Contents  
- Case studies applying RLHF principles to support autistic and neurodiverse learners  
- Rubric-based feedback generators simulating empathetic instructional responses  
- Prompt design experiments grounded in sociology, pedagogy, and cultural analysis  
- Reflections on alignment from a humanities-informed perspective

## Why It Matters  
This work explores how AI systems can be trained and evaluated using humanistic rubrics — especially in emotionally complex or educational contexts. It contributes to broader conversations around AI alignment, inclusive instruction, and symbolic reasoning in LLMs.

## Credentials  
- NSF-funded PhD in Sociology, Northwestern University  
- 1,500+ citations on Google Scholar  
- Published author with Russell Sage Foundation & Twayne Publishers  
- Former professor of sociology (1989–2017)  
- Contributor to RLHF projects at Snorkel AI, Outlier AI, and Handshake AI

## Contact  
Interested in collaborating on RLHF, prompt design, or inclusive AI training?  
Reach me via [LinkedIn](https://www.linkedin.com/in/jeremyhein) or email: heinj@uwec.edu

## Discoverability  
To help others find this work, feel free to share or cite this repo using keywords like:  
RLHF, AI alignment, neurodiversity, rubric-based feedback, symbolic interactionism, inclusive pedagogy, prompt engineering, musicology, comparative religion
